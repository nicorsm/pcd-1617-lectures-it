# PCD Module 4.2

**Sistemi distribuiti: qualche algoritmo**

## Algoritmi distribuiti

- Sfide principali: non ci sono clock e memorie condivise, fallimenti. 
- Idea generale: utilizzo di clock logici e relazione _happened-before_ per definire un ordine tra eventi correlati.
- Presupposizioni per molti algoritmi:
	- sistemi asincroni senza fallimenti - finiti ma tempo di consegna non conosciuto a priori
	- sistemi sincroni quando si parla di errori - timeout
- Principali categorie:
	- **coordinamento**
	- **osservazione**
	- **controllo**
	
### Mutex e CS

- Analogo al problema nel caso concorrente, qui i processi sono distribuiti
- Proprietà della CS:
	- **sicurezza**: due processi non devono avere il permesso di essere nella CS simultaneamente
	- **vitalità**: ogni richiesta alla CS deve essere eventualmente garantita
	- **equità**: richieste diverse devono essere garantite nell'ordine che sono state fatte.

## Algoritmo di Agrawala

- per richiedere una risorsa, il processo invia un messaggio timestamp a tutti i processi
- alla ricezione della richiesta da qualsiasi altro processo, il processo invia un messaggio OK se non è interessato ad entrare nella CS o se la richiesta stessa ha un timestamp più alto. Altrimenti tale processo è mantenuto in una coda.
- per rilasciare una risorsa, il processo $P_i$ invia OK a tutti gli altri processi in coda
- $P_i$ viene concesso alla risorsa quando è richiesto dalla risorsa e ha ricevuto OK da tutti gli altri processi in risposta al messaggio di richiesta.

```
Pi::var    pendingQ: list of process ids initially null    myts: integer timestamp initially infinity    numOK: integer initially 0request:    myts := logical_clock    send req with myts to all other processes    numOK := 0receive(u,req):    if (u.myts < myts)       send OK to process u.pid    else       append(pendingQ,u.pid)receive(u,OK):    numOK := numOK + 1    if (numOK == N-1)enter_CSrelease:    myts := infinity    for each pid in pendingQ       send OK to pid    empty(pendingQ)
```

- Completamente decentralizzato
- Numero di messaggi: $2 \times (N-1)$
- Lavora con canali non necessariamente FIFO

## Algoritmo centralizzato

- C'è un coordinatore che assegna i token
- Punto chiave: **equità**
	- le richieste devono avere accesso in accordo con la relazione _happened-before_
	- se $s \rightarrow t$, la richiesta $s$ deve essere servita prima di $t$, con $s,t$ = due stati locali corrispondenti a eventi di richiesta
	- se una richiesta $t$ arriva al coordinatore prima di $s$, il coordinatore dev'essere in grado che c'è una richiesta in sospeso dal processo $P$ relativo a $s$.
	- dal momento che $s \rightarrow t$, $r$ ha informazioni su $s$: il processo $P$ correlato a $t$ ha bisogno solamente di appoggiarsi sul coordinatore per le richieste che conosce
	- il coordinatore può ritardare la ricezione del messaggio $t$ finchè tutte le richieste prima di $t$ vengono ricevute.
	- informazioni sulle richieste conosciute nello stato $s$ sono catturate tramite un vettore $s.v$, dove $s.v[j]$ rappresenta il numero di richieste fatte da $P_j$ che precedono causalmente lo stato $s$.
- Idea
	- i processi cooperano portandosi a cavallo del porco (piggybacking) il vettore clock $v$ su tutti i processi in uscita.  
	- il processo coordinatore ritarda una richiesta $t$ finchè tutte le richieste prima di $t$ vengono ricevute.
		- `redone` = vettore t.c. `reqdone[i]` = n° di richieste fatte da $P_i$ che sono state soddisfatte.
		- `reqlist` = lista di richieste ricevute da $P_0$ che non sono state ancora soddisfatte
		- richieste ammissibili = una richiesta $w$ è ammissibile se $w.v$ è almeno `reqdone` - non ci sono richieste accadute prima di $w$ e non sono state già soddisfatte

```
Peers

Pi:: var    v: array[1..N] of integer := [0]    inCS: boolean := falseTo request:    v[i] := v[i] + 1    send (req, v) to P0Upon receive(token) from P0:    inCS := trueTo release:    send token to P0    inCS := falseUpon receive(u):    v:= max(v,u.v)
    
Coordinator

P0::var    reqDone: array[1..N] of integer := [0]    reqList: list of (pid, reqvector) := empty    haveToken: boolean := trueUpon receive(u,req):    append(reqList,u)    if (haveToken)checkReq()Upon receive(u,token):    haveToken := true    checkReq()checkReq:    eligible := {w in reqList|for each j, j != w.p:                 w.v[j] <= reqDone[j] }    if (eligible != {})       w := first(eligible)       delete(reqList,w)       reqDone[w.p] := reqDone[w.p] + 1       send token to Pw.p       haveToken := false
```

### Ulteriori approcci

- **Sistema di voto basato su quorum**
	- gli approcci basati su token sono vulnerabili ai fallimenti dei processi che trattengono i token
	- le strategie basate su quorum non hanno un singolo punto di fallimento
	- **Elezione del leader**:
		- si sceglie un processo in un insieme di $N$ processi
		- basato su superimporre una topologia logica ad anello nella rete sottostante per eseguire funzioni di controllo
		- strategia largamente usata per scegliere coordinatori negli algoritmi centralizzati.
	 
## Algoritmo di Chang-Roberts

- Presupposto: ogni processo ha un PID univoco
- Idea: 
	- il processo con il PID più alto viene scelto
	- uno o più processi possono spontaneamente svegliarsi e iniziare un'elezione
	- un processo:
		- invia il messaggio di elezione assieme al suo ID alla sua sinistra, se non ha visto alcun messaggio con un identificatore più alto del suo
		- inoltra qualsiasi messaggio che ha un ID maggiore del suo, altrimenti digerisce il messaggio
		- se un processo riceve il suo stesso messaggio, si dichiara leader e propaga il messaggio leader

```
Pi::var    myid: integer    awake: boolean := false    leaderId: integer := nullTo initiate election:    send (election,myid) to P(i-1)    awake := trueUpon receiving a message (election,j):    if (j > myid)       send (election,j) to P(i-1)    else if (j == myid)       send (leader,myid) to P(i-1)    else if ((j < myid) and !awake)       send (election, myid) to P(i-1)    awake := trueUpon receiving a message (leader,j):    leaderId := j    if (j != myid)       send (leader,j) to P(i-1)
``` 

- Numero di messaggi scambiati:
	- caso peggiore: $sum(1,N) = O(N^2) + N$ messaggi leader
	- caso migliore: $O(N)$
	- media: $O(N log N)$

### Stato globale

- Catturare lo stato globale del sistema distribuito da un singolo processo:
	- **stato globale**: insieme di stati locali che sono tutti concorrenti con gli altri, in accordo col modello _happened-before_
	- per molte applicazioni, è abbastanza catturare uno stato globale che è accaduto in passato, non il corrente
- Un algorimto che cattura lo stato globale è chiamato **Global snapshot algorithm**
- Sfida: un numero consistente di stati globali non sono semplicemente il prodotto di stati locali.
	- **taglio consistente**: a global state S where ∀ event e | e = receive(msg),   S ∋ e', where e' = send(msg), e' → e 

## Algoritmo snapshot Chandy-Lamport

- Prende uno snapshot globale consistende di un sistema distribuito, calcolando un taglio consistente. 
- Sfide:
	- assicurare che gli stati locali siano concorrenti
	- fare lo snapshot senza bloccare i processi
	- catturare lo stato dei canali (meccanismo dei _marker_).
- Presupposti: tutti i canali sono unidirezionali e FIFO.
- Idea: 
	- ogni processo ha una variabile colore (rosso/bianco): lo snapshot calcolato corrisponde allo stato del sistema prima che il processo diventa rosso.
	- tutti i processi sono inizialmente bianchi
	- dopo aver registrato uno stato locale, un processo diventa rosso: lo stato del processo locale è semplicemente lo stato prima che diventi rosso
	- per registrare lo stato del canale, una volta che il processo diventa rosso, invia un messaggio marker a tutti i canali in uscita prima di inviare ogni altro messaggio. Un processo deve diventare rosso alla ricezione di un marker se non l'ha già fatto. Avendo i canali FIFO, nessun processo bianco riceve un messaggio inviato da un processo rosso - ciò assicura che lo stato locale sia mutualmente concorrente. Lo stato dei canali è dato dai messaggi inviati da un processo bianco e ricevuti da un processo rosso (messaggi in transito quando lo snapshot è stato preso).

```
Pi::var    color: {white,red} := white    // assume k incoming channels    chan: array[1..k] of queues of msg := empty // state of the channels to be recorded    closed: array[1..k] of boolean := [false]turn_red() enabled if (color = white):    save_local_state    color := red    send maker to all neighborsUpon receive(marker) on incoming channel j:    if (color = white)       turn_red()    closed[j] := trueUpon receive(program_message) on incoming channel j:    if (color = red and not closed[j])       append(chan[j], program_message)
```

**Ulteriori problematiche**: osservando _predicati globali_: lineari, regolari, congiuntivi, predicati dei canali. Applicazioni: ricerca deadlock, ricerca terminazioni qq, computazione funzioni globali.

## Ordinamento messaggi causale

Avendo una computazione completamente asincrona, non abbiamo restrizioni nell'ordinamento dei messaggi (nondeterminismo e concorrenza all'ennesima potenza). A volte può essere utile ridurre il nondeterminismo restringendo i possibili ordinamenti dei messaggi possibili nel sistema.

Da una computazione FIFO-ordered all'ordinamento causale: dati due messaggi $m_1$, $m_2$ tali che $send(m_1) \rightarrow send(m_2)$, allora $rec(m_1) \rightarrow rec(m_2)$. Non ci sono sorpassi.

Algoritmo che assicura l'ordinamento causale:

- ogni processo mantiene una matrice $m$ di interi, `s.m[j,k]` = numero di msg inviati da un processo $P_j$ a $P_k$ così come conosciuto da $P_i$ nello stato $s$.
- ogni qualvolta un msg è inviato da $P_i$ a $P_j$, $m$ è portata a cavallo del porco col messaggio
- `m[i,j]` è incrementato per rifletter che un altro messaggio è stato inviato da $P_i$ a $P_j$
- quando un messaggio è ricevuto dal sistema, viene controllato se è qualificato prima di essere inviato a $P_i$. Un messaggio $u$ è qualificato ad essere ricevuto in uno stato $s$ da $P_i$ quando un numero di messaggi inviati da qualsiasi processo $P_k$ a $P_i$ è riportato da $u.m$ è $\leq$ al numero dei registrati in $s.m$. 
- se non qualificato, il messaggio è bufferato finchè può essere ricevuto

```
Pi::var    m: array[1..N,1..N] of integer := 0send(u,t) to Pj:    t.m := s.m    t.m[i,j] := t.m[i,j] + 1receive(u,t) : eligible if ∀ k: s.m[k,i] >= u.m[k,i] t.m := max(s.m,u.m)t.m[u.p,i] := t.m[u.p,i] + 1
```

**Ulteriori considerazioni**

- Ordinamento sincrono e totale: più forte dell'ordine causale, imposta una coordinazione tale che tutti i messaggi possano essere trattati come istantaneamente logici.
- Gli algoritmi per sistemi sincroni sono più facili da implementare

## Sincronizzatori

- La progettazione di sistemi distribuiti è più facile se si assume che la rete sottostante sia sincrona invece che asincrona. Si possono così simulare reti sincrone su asincrone (tempo di trasmissione = 0), presupponendo l'assenza di errori o ritardi massimi.
- Meccanismi: 
	- **impulsi** : contatore ad ogni processo con la proprietà che qualsiasi messaggio inviato in un impulso $i$ è ricevuto all'impulso $i$. 
	- **sincronizzatori**: meccanismo che indica ad un processo quando può generare un impulso.
- Complessità: 
	- **dei messaggi**: numero addizionale di messaggi richiesti dal sincronizzatore per simulare un algoritmo sincrono su una rete asincrona
	- **del tempo**: numero di unità di tempo richieste per simulare un impulso
- Idea
	- Ogni processo invia esattamente un messaggio a tutti i vicini ad ogni impulso
	- Se un processo è al giro $i$ e riceve un messaggio con impulso $i+1$, buffera tale messaggio e aspetta per il messaggio con impulso $i$.

```
Pj::var    pulse: integer := 0round i:    pulse := pulse + 1    simulate the round i of the synch algorithm    send msg to all neighbors with pulse    wait for exactly one msg from each neighbor with (pulse = i)
```  

## Consenso

- Problema fondamentale nella programmazione distribuita: trovare un accordo tra processi distribuiti sul valore di qualche proprietà, su qualche azione da fare, ecc.
- In reti **asincrone**, la presenza di anche un singolo fallimento/morte di un processo non annunciato, rende impossibile la soluzione
- Date le proprietà generali del consenso, tutti i problemi sono impossibili da risolvere nel caso di fallimento di processi in reti completamente asincrone

### Consenso con sincronia

- Può essere presupposto un limite superiore sul ritardo dei messaggi e sulla durata delle azioni compiute dai processi
- Tipi di falle:
	- **crash**: una falla corrisponde allo stop del processore
	- **crash + link**: un processore può crashare o un collegamento spegnersi
	- **omissione**: un processo fallisce sia l'invio di un sottoinsieme proprio di messaggi che vengono richiesti dall'algoritmo o dal ricevente solo un sottoinsieme di messaggi inviati ad esspo
	- **fallimento bizantino**: un processore fallisce esibendo un comportamento arbitrario.

### Consenso per modello di crash

- Insieme di valori $v$ totalmente ordinato dove il consenso è richiesto: ogni processo $P_i$ ha un valore in input $v_i$.
- Obiettivo del protocollo: impostare il valore $y$ ad ogni processo tale che i seguenti vincoli siano soddisfatti
	- **accordo**: due processi non difettosi non possono decidere su valori diversi
	- **validità**: se tutti i processi propongono lo stesso valore, il valore deciso dovrebbe essere quello proposto
	- **terminazione**: il sistema raggiunge un accordo in un tempo finito.
- Idea:
	- ogni processo mantiene $V$, l'insieme di valori conosciuti che sono stati proposti dai processori del sistema. Inizialmente il processo conosce solo il proprio valore.
	- algoritmo a turni: ogni processo corretto esegue $f+1$ turni, $f$ = numero massimo di processori che possono fallire
	- ad ogni turno, un processo invia a tutti i processi i valori da $V$ che non sono stati già inviati. Un processo $P_i$ riceve il valore inviato da $P_j$. Assunzione sincrona: aspettando per un tempo fisso predefinito, dopodichè si assume $P_j$ crashato.
- Numero di messaggi richiesti: $O((f+1)N^2)$

```
Pi::varV: set of values := { v[i] }for k := 1 to f + 1 do    send {v in V | Pi has not already sent v} to all    receive Sj from all process Pj, j != i    V := V U Sjy := min(V)
```

### Consenso sotto falle bizantine

- Processi difettosi possono avere un comportamento arbitrario (es. inviare valori sbagliati)
- **Problema dell'Accordo Generale Bizantino (BGA)**: progettazione di un protocollo per il quale i fedeli generali (processi corretti) possono coordinare le loro azioni (decidendo di attacco o ritirata complessivamente) nonostante i processi infidi (difettosi)
- Risultato (teorema): non ci sono protocolli $f$-resilienti per BGA se $N \leq 3f$, $N$ = numero totale di processi, $f$ = numero di processi difettosi
- Idea
	- $f+1$ turni, $f$ processori difettosi
	- coordinatore rotante (king), almeno 1 giro ha un king non difettoso
	- il processore $P_i$ presuppone di essere il coordinatore o il king al giro $k$
	- 2 stadi:
		- 1°: ogni processore scambia il suo valore a tutti gli altri processori e basato su $V$ determina la stima – variabile `myvalue`
		- 2°: riceve il valore dal coordinatore. Se non c'è nessun valore ricevuto (coordinatore fallito), si presuppone null. Dopodichè decide se mantenere il suo valore o il valore king. La decisione è basata sulla molteplicità di `myvalue` nel vettore $V$: se $V$ ha più di $N/2+f$ copie di `myvalue`, allora `myvalue` è scelto per $V[i]$, altrimenti viene usato il valore king.

```
Pi::var    V: array[1..N] of values := {v[i] = x, v[j] = not defined}for k := 1 to f + 1 do    first phase:       send V[i] to all other processors       set V[j] (j != i) to the value received from Pj       myvalue := majority in the vector V (not defined, if no majority)    second phase:       if (k == i) // I’m the king in this round           send myvalue to all other processors       receive king value from Pk       if V vector has more than N/2 + f copies of my values           V[i] := myvalue       else
           V[i] := kingvaluey := V[i]
```

#### Ulteriori esplorazioni

**Paxos**: famiglia di protocolli per risolvere il consenso in una rete su processori non affidabili, compreso un spettro di trade-off tra il numero di processori, numero di ritardi di messaggio prima di imparare il valore concordato, il livello di attività dei singoli partecipanti, il numero di messaggi inviati e tipi di guasti.

Usato quando la _durabilità_ è richiesta, es. per replicare un file o un db.


### Rivelatore di guasti

Modulo utile nei programmi distribuiti, incorpora tutti i dettagli di timeout in un modulo responsabile della gestione della conoscenza sui processi che possono essere difettosi.

Senza questo modulo, ogni receive bloccante deve avere un timeout. Con questo modulo, si aspetta un messaggio $m$ da $P_i$, altrimenti $P_i$ è sospetto: il programma diventa non bloccante a discapito di errori nei processi.

Il modulo è responsabile di mantenere il valore di predicati sospetti a tutti i processi corretti. Presupposto: una volta che il processo è fallito, è fallito. Crash, no modelli bizantini.

Idea: Il rivelatore è basato su 2 attività
- il rilevatore di ciascun processore invia il relativo elenco di sospettoso per tutti gli altri processori infinitamente spesso- Alla ricezione di tale messaggio, un rilevatore di aggiungere l'elenco di sospettoso di Pi e rimuove Pi dall'elenco sospettoso se presente

